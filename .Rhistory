colnames(X) <- paste0("X",1:ncol(X))
ressynth<-drfwithVI(X, Y, B=1, num.trees=num.trees)
ressynth$VI
source("~/Studium/PhD/Projects with Marc/Github/DRFvarimporance/genData.R")
tmp<-genData(dataset = dataset, n = n, p = p)
X<-tmp$X
Y<-as.matrix(tmp$y)
colnames(X) <- paste0("X",1:ncol(X))
ressynth<-drfwithVI(X, Y, B=1, num.trees=num.trees)
ressynth$VI
ressynth<-drfwithVI(X, Y, B=1, num.trees=num.trees, random.features=50)
?drf
ressynth<-drfwithVI(X, Y, B=1, num.trees=num.trees, num.features=50)
ressynth$VI
debugSource("~/Studium/PhD/Projects with Marc/Github/DRFvarimporance/evaluation.R")
debugSource("~/Studium/PhD/Projects with Marc/Github/DRFvarimporance/drfnew_v2.R")
library(kernlab)
library(drf)
library(Matrix)
# Load necessary libraries
library(mvtnorm) # for generating multivariate normal random variables
library(ks)
library(dplyr)
library(kableExtra)
library(copula)
source("drfnew_v2.R")
#source("applications")
source("genData.R")
source("evaluation.R")
set.seed(10)
### Continue with more fancy examples!!!
n<-500
ntest<-round(n*0.1)
num.trees<-3000
##### Continue with the collection of the DRF datasets ######
## Discuss with Julie: Could be super interesting to use a medical dataset with
## patients, whereby X is the patients characteristics and Y is a stream of measurements
##(though would probably need Gaussian processes in a first step)
## Step 2: Do Analysis
### 2.a) if the dataset is synthetic, we can check the correct variable ordering
evalsynthetic(dataset="meanshift", L=10, n=n, p=10, num.trees = num.trees)
debug(drfwithVI)
library(kernlab)
library(drf)
library(Matrix)
# Load necessary libraries
library(mvtnorm) # for generating multivariate normal random variables
library(ks)
library(dplyr)
library(kableExtra)
library(copula)
source("drfnew_v2.R")
#source("applications")
source("genData.R")
source("evaluation.R")
set.seed(10)
### Continue with more fancy examples!!!
n<-500
ntest<-round(n*0.1)
num.trees<-3000
##### Continue with the collection of the DRF datasets ######
## Discuss with Julie: Could be super interesting to use a medical dataset with
## patients, whereby X is the patients characteristics and Y is a stream of measurements
##(though would probably need Gaussian processes in a first step)
## Step 2: Do Analysis
### 2.a) if the dataset is synthetic, we can check the correct variable ordering
evalsynthetic(dataset="meanshift", L=10, n=n, p=10, num.trees = num.trees)
p=10
dataset="meanshift"
tmp<-genData(dataset = dataset, n = n, p = p)
X<-tmp$X
Y<-as.matrix(tmp$y)
colnames(X) <- paste0("X",1:ncol(X))
ressynth<-drfwithVI(X, Y, B=1, num.trees=num.trees, num.features=10)
debug(drfwithVI)
ressynth<-drfwithVI(X, Y, B=1, num.trees=num.trees, num.features=10)
wbar<- rep(1/ntest,ntest)
wbar
diag(ntest)
sweep(diag(ntest), 2, wbar, "-")
wall_wbar
wall_wbar<-sweep(diag(ntest), 2, wbar, "-")
wall_wbar
wall_wbar %*% K %*% t(wall_wbar)
K
ntest
sample.splitting
ressynth<-drfwithVI(X, Y, B=1, num.trees=num.trees, num.features=10)
debugSource("~/Studium/PhD/Projects with Marc/Github/DRFvarimporance/drfnew_v2.R")
debug(drfnew)
debug(drfwithVI)
ressynth<-drfwithVI(X, Y, B=1, num.trees=num.trees, num.features=10)
ressynth<-drfwithVI(X, Y, B=1, num.trees=num.trees, num.features=10)
ressynth<-drfwithVI(X, Y, B=1, num.trees=num.trees, num.features=10)
wall_wbar %*% K %*% t(wall_wbar)
I
wall_wbar
source("~/Studium/PhD/Projects with Marc/Github/DRFvarimporance/drfnew_v2.R")
library(kernlab)
library(drf)
library(Matrix)
# Load necessary libraries
library(mvtnorm) # for generating multivariate normal random variables
library(ks)
library(dplyr)
library(kableExtra)
library(copula)
source("drfnew_v2.R")
#source("applications")
source("genData.R")
source("evaluation.R")
set.seed(10)
### Continue with more fancy examples!!!
n<-500
ntest<-round(n*0.1)
num.trees<-3000
##### Continue with the collection of the DRF datasets ######
## Discuss with Julie: Could be super interesting to use a medical dataset with
## patients, whereby X is the patients characteristics and Y is a stream of measurements
##(though would probably need Gaussian processes in a first step)
## Step 2: Do Analysis
### 2.a) if the dataset is synthetic, we can check the correct variable ordering
evalsynthetic(dataset="meanshift", L=10, n=n, p=10, num.trees = num.trees)
debugSource("~/Studium/PhD/Projects with Marc/Github/DRFvarimporance/evaluation.R")
library(kernlab)
library(drf)
library(Matrix)
# Load necessary libraries
library(mvtnorm) # for generating multivariate normal random variables
library(ks)
library(dplyr)
library(kableExtra)
library(copula)
source("drfnew_v2.R")
#source("applications")
source("genData.R")
source("evaluation.R")
set.seed(10)
### Continue with more fancy examples!!!
n<-500
ntest<-round(n*0.1)
num.trees<-3000
##### Continue with the collection of the DRF datasets ######
## Discuss with Julie: Could be super interesting to use a medical dataset with
## patients, whereby X is the patients characteristics and Y is a stream of measurements
##(though would probably need Gaussian processes in a first step)
## Step 2: Do Analysis
### 2.a) if the dataset is synthetic, we can check the correct variable ordering
evalsynthetic(dataset="meanshift", L=10, n=n, p=10, num.trees = num.trees)
debugSource("~/Studium/PhD/Projects with Marc/Github/DRFvarimporance/evaluation.R")
debug(evalsynthetic)
library(kernlab)
library(drf)
library(Matrix)
# Load necessary libraries
library(mvtnorm) # for generating multivariate normal random variables
library(ks)
library(dplyr)
library(kableExtra)
library(copula)
source("drfnew_v2.R")
#source("applications")
source("genData.R")
source("evaluation.R")
set.seed(10)
### Continue with more fancy examples!!!
n<-500
ntest<-round(n*0.1)
num.trees<-3000
##### Continue with the collection of the DRF datasets ######
## Discuss with Julie: Could be super interesting to use a medical dataset with
## patients, whereby X is the patients characteristics and Y is a stream of measurements
##(though would probably need Gaussian processes in a first step)
## Step 2: Do Analysis
### 2.a) if the dataset is synthetic, we can check the correct variable ordering
evalsynthetic(dataset="meanshift", L=10, n=n, p=10, num.trees = num.trees)
debug(evalsynthetic)
library(kernlab)
library(drf)
library(Matrix)
# Load necessary libraries
library(mvtnorm) # for generating multivariate normal random variables
library(ks)
library(dplyr)
library(kableExtra)
library(copula)
source("drfnew_v2.R")
#source("applications")
source("genData.R")
source("evaluation.R")
set.seed(10)
### Continue with more fancy examples!!!
n<-500
ntest<-round(n*0.1)
num.trees<-3000
##### Continue with the collection of the DRF datasets ######
## Discuss with Julie: Could be super interesting to use a medical dataset with
## patients, whereby X is the patients characteristics and Y is a stream of measurements
##(though would probably need Gaussian processes in a first step)
## Step 2: Do Analysis
### 2.a) if the dataset is synthetic, we can check the correct variable ordering
evalsynthetic(dataset="meanshift", L=10, n=n, p=10, num.trees = num.trees)
debug(evalsynthetic)
evalsynthetic(dataset="meanshift", L=10, n=n, p=10, num.trees = num.trees)
ressynth
ressynth$VI
ressynth$VI
resmat
res
library(kernlab)
library(drf)
library(Matrix)
# Load necessary libraries
library(mvtnorm) # for generating multivariate normal random variables
library(ks)
library(dplyr)
library(kableExtra)
library(copula)
source("drfnew_v2.R")
#source("applications")
source("genData.R")
source("evaluation.R")
set.seed(10)
### Continue with more fancy examples!!!
n<-500
ntest<-round(n*0.1)
num.trees<-3000
##### Continue with the collection of the DRF datasets ######
## Discuss with Julie: Could be super interesting to use a medical dataset with
## patients, whereby X is the patients characteristics and Y is a stream of measurements
##(though would probably need Gaussian processes in a first step)
## Step 2: Do Analysis
### 2.a) if the dataset is synthetic, we can check the correct variable ordering
evalsynthetic(dataset="sdshift", L=10, n=n, p=10, num.trees = num.trees)
library(kernlab)
library(drf)
library(Matrix)
# Load necessary libraries
library(mvtnorm) # for generating multivariate normal random variables
library(ks)
library(dplyr)
library(kableExtra)
library(copula)
source("drfnew_v2.R")
#source("applications")
source("genData.R")
source("evaluation.R")
set.seed(10)
### Continue with more fancy examples!!!
n<-500
ntest<-round(n*0.1)
num.trees<-3000
##### Continue with the collection of the DRF datasets ######
## Discuss with Julie: Could be super interesting to use a medical dataset with
## patients, whereby X is the patients characteristics and Y is a stream of measurements
##(though would probably need Gaussian processes in a first step)
## Step 2: Do Analysis
### 2.a) if the dataset is synthetic, we can check the correct variable ordering
evalsynthetic(dataset="distshift", L=10, n=n, p=10, num.trees = num.trees)
library(kernlab)
library(drf)
library(Matrix)
# Load necessary libraries
library(mvtnorm) # for generating multivariate normal random variables
library(ks)
library(dplyr)
library(kableExtra)
library(copula)
source("drfnew_v2.R")
#source("applications")
source("genData.R")
source("evaluation.R")
set.seed(10)
### Continue with more fancy examples!!!
n<-500
ntest<-round(n*0.1)
num.trees<-3000
##### Continue with the collection of the DRF datasets ######
## Discuss with Julie: Could be super interesting to use a medical dataset with
## patients, whereby X is the patients characteristics and Y is a stream of measurements
##(though would probably need Gaussian processes in a first step)
## Step 2: Do Analysis
### 2.a) if the dataset is synthetic, we can check the correct variable ordering
evalsynthetic(dataset="bivariatesynthetic", L=10, n=n, p=10, num.trees = num.trees)
library(kernlab)
library(drf)
library(Matrix)
# Load necessary libraries
library(mvtnorm) # for generating multivariate normal random variables
library(ks)
library(dplyr)
library(kableExtra)
library(copula)
source("drfnew_v2.R")
#source("applications")
source("genData.R")
source("evaluation.R")
set.seed(10)
### Continue with more fancy examples!!!
n<-500
ntest<-round(n*0.1)
num.trees<-3000
##### Continue with the collection of the DRF datasets ######
## Discuss with Julie: Could be super interesting to use a medical dataset with
## patients, whereby X is the patients characteristics and Y is a stream of measurements
##(though would probably need Gaussian processes in a first step)
## Step 2: Do Analysis
### 2.a) if the dataset is synthetic, we can check the correct variable ordering
evalsynthetic(dataset="copulasynthetic", L=10, n=n, p=10, num.trees = num.trees)
library(kernlab)
library(drf)
library(Matrix)
# Load necessary libraries
library(mvtnorm) # for generating multivariate normal random variables
library(ks)
library(dplyr)
library(kableExtra)
library(copula)
source("drfnew_v2.R")
#source("applications")
source("genData.R")
source("evaluation.R")
set.seed(10)
### Continue with more fancy examples!!!
n<-500
ntest<-round(n*0.1)
num.trees<-3000
##### Continue with the collection of the DRF datasets ######
## Discuss with Julie: Could be super interesting to use a medical dataset with
## patients, whereby X is the patients characteristics and Y is a stream of measurements
##(though would probably need Gaussian processes in a first step)
## Step 2: Do Analysis
### 2.a) if the dataset is synthetic, we can check the correct variable ordering
evalsynthetic(dataset="GP", L=10, n=n, p=10, num.trees = num.trees)
library(kernlab)
library(drf)
library(Matrix)
# Load necessary libraries
library(mvtnorm) # for generating multivariate normal random variables
library(ks)
library(dplyr)
library(kableExtra)
library(copula)
source("drfnew_v2.R")
#source("applications")
source("genData.R")
source("evaluation.R")
set.seed(10)
### Continue with more fancy examples!!!
n<-500
ntest<-round(n*0.1)
num.trees<-3000
##### Continue with the collection of the DRF datasets ######
## Discuss with Julie: Could be super interesting to use a medical dataset with
## patients, whereby X is the patients characteristics and Y is a stream of measurements
##(though would probably need Gaussian processes in a first step)
## Step 2: Do Analysis
### 2.a) if the dataset is synthetic, we can check the correct variable ordering
evalsynthetic(dataset="GP", L=10, n=n, p=10, num.trees = num.trees)
source("C:/Users/Jeff/OneDrive/Dokumente/Studium/PhD/Projects with Marc/Github/DRFvarimporance/drfnew_v2.R")
library(kernlab)
library(drf)
library(Matrix)
# Load necessary libraries
library(mvtnorm) # for generating multivariate normal random variables
library(ks)
library(dplyr)
library(kableExtra)
library(copula)
source("drfnew_v2.R")
#source("applications")
source("genData.R")
source("evaluation.R")
set.seed(10)
### Continue with more fancy examples!!!
n<-500
ntest<-round(n*0.1)
num.trees<-3000
##### Continue with the collection of the DRF datasets ######
## Discuss with Julie: Could be super interesting to use a medical dataset with
## patients, whereby X is the patients characteristics and Y is a stream of measurements
##(though would probably need Gaussian processes in a first step)
## Step 2: Do Analysis
### 2.a) if the dataset is synthetic, we can check the correct variable ordering
evalsynthetic(dataset="GP", L=10, n=n, p=10, num.trees = num.trees)
debug(evalsynthetic)
### 2.a) if the dataset is synthetic, we can check the correct variable ordering
evalsynthetic(dataset="GP", L=10, n=n, p=10, num.trees = num.trees)
library(kernlab)
library(drf)
library(Matrix)
# Load necessary libraries
library(mvtnorm) # for generating multivariate normal random variables
library(ks)
library(dplyr)
library(kableExtra)
library(copula)
source("drfnew_v2.R")
#source("applications")
source("genData.R")
source("evaluation.R")
set.seed(10)
### Continue with more fancy examples!!!
n<-500
ntest<-round(n*0.1)
num.trees<-3000
##### Continue with the collection of the DRF datasets ######
## Discuss with Julie: Could be super interesting to use a medical dataset with
## patients, whereby X is the patients characteristics and Y is a stream of measurements
##(though would probably need Gaussian processes in a first step)
## Step 2: Do Analysis
### 2.a) if the dataset is synthetic, we can check the correct variable ordering
evalsynthetic(dataset="meanshift", L=10, n=n, p=10, num.trees = num.trees)
library(kernlab)
library(drf)
library(Matrix)
# Load necessary libraries
library(mvtnorm) # for generating multivariate normal random variables
library(ks)
library(dplyr)
library(kableExtra)
library(copula)
source("drfnew_v2.R")
#source("applications")
source("genData.R")
source("evaluation.R")
set.seed(10)
### Continue with more fancy examples!!!
n<-1000
ntest<-round(n*0.1)
num.trees<-3000
##### Continue with the collection of the DRF datasets ######
## Discuss with Julie: Could be super interesting to use a medical dataset with
## patients, whereby X is the patients characteristics and Y is a stream of measurements
##(though would probably need Gaussian processes in a first step)
## Step 2: Do Analysis
### 2.a) if the dataset is synthetic, we can check the correct variable ordering
evalsynthetic(dataset="GP", L=10, n=n, p=10, num.trees = num.trees)
library(drf)
predict.drf
?predict.drf
library(MASS)
library(drf)
### unconditional example!!
set.seed(1)
n<-200
p<-2
X<-matrix(rnorm(p*n, 1), nrow=n)
simulate_P_theta <- function(M, theta){ mvrnorm(M, mu=theta, Sigma=diag(length(theta)))   }
derivative_log_density<-function(theta, Y){sweep(Y,2, theta, "-")  }
res<-MMDestimation(X, M=5, k=NULL, w=NULL, numit=2000, simulate_P_theta, derivative_log_density, theta_init=rep(0,p))
res
###DRF example!
set.seed(2)
n<-2000
beta1<-1
beta2<--1.8
d<-1
# Model Simulation
X<-mvrnorm(n = n, mu=c(0,0), Sigma=matrix(c(1,0,0,1), nrow=2,ncol=2))
#X<-mvrnorm(n = n, mu=c(0,0), Sigma=diag(2))
u<-rnorm(n=n, sd = 1)#sqrt(exp(X[,1]))
Y<- matrix(beta1*X[,1] + beta2*X[,2] + u, ncol=1)
# Choose an x that is not too far out
x<-matrix(c(1,1),ncol=2)
## Fit the new DRF framework
drf_fit <- drf(X=X, Y=Y, num.trees=5000, min.node.size = 15,  ci.group.size = 1)
## predict weights
DRF = predict(drf_fit, newdata=x)
weights <- DRF$weights[1,]
sum(weights*Y)
simulate_P_theta <- function(M, theta){ mvrnorm(M, mu=theta, Sigma=diag(length(theta)))   }
derivative_log_density<-function(theta, Y){sweep(Y,2, theta, "-")  }
res<-MMDestimation(Y, M=5, k=NULL, w=weights, numit=1000, simulate_P_theta, derivative_log_density, theta_init=rep(0,d))
#res<-MMDestimation(Y, M=5, k=NULL, w=rep(1/n,n), numit=1000, simulate_P_theta, derivative_log_density, theta_init=rep(0,d))
res
source("C:/Users/Jeff/OneDrive/Today/MMD_Estimation/MMD_minimization.R")
library(MASS)
library(drf)
### unconditional example!!
set.seed(1)
n<-200
p<-2
X<-matrix(rnorm(p*n, 1), nrow=n)
simulate_P_theta <- function(M, theta){ mvrnorm(M, mu=theta, Sigma=diag(length(theta)))   }
derivative_log_density<-function(theta, Y){sweep(Y,2, theta, "-")  }
res<-MMDestimation(X, M=5, k=NULL, w=NULL, numit=2000, simulate_P_theta, derivative_log_density, theta_init=rep(0,p))
res
###DRF example!
set.seed(2)
n<-2000
beta1<-1
beta2<--1.8
d<-1
# Model Simulation
X<-mvrnorm(n = n, mu=c(0,0), Sigma=matrix(c(1,0,0,1), nrow=2,ncol=2))
#X<-mvrnorm(n = n, mu=c(0,0), Sigma=diag(2))
u<-rnorm(n=n, sd = 1)#sqrt(exp(X[,1]))
Y<- matrix(beta1*X[,1] + beta2*X[,2] + u, ncol=1)
# Choose an x that is not too far out
x<-matrix(c(1,1),ncol=2)
## Fit the new DRF framework
drf_fit <- drf(X=X, Y=Y, num.trees=5000, min.node.size = 15,  ci.group.size = 1)
## predict weights
DRF = predict(drf_fit, newdata=x)
weights <- DRF$weights[1,]
sum(weights*Y)
simulate_P_theta <- function(M, theta){ mvrnorm(M, mu=theta, Sigma=diag(length(theta)))   }
derivative_log_density<-function(theta, Y){sweep(Y,2, theta, "-")  }
res<-MMDestimation(Y, M=5, k=NULL, w=weights, numit=1000, simulate_P_theta, derivative_log_density, theta_init=rep(0,d))
#res<-MMDestimation(Y, M=5, k=NULL, w=rep(1/n,n), numit=1000, simulate_P_theta, derivative_log_density, theta_init=rep(0,d))
res
